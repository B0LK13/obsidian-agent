name: Evaluation Quality Gates

on:
  pull_request:
    branches: [main, develop]
  push:
    branches: [main]
  schedule:
    # Nightly full evaluation at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    # Manual trigger

jobs:
  quick-eval-pr:
    name: Quick Eval (50 queries, warn-only)
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 10
      
      - name: Install dependencies
        run: pnpm install
      
      - name: Run Quick Evaluation (50 queries)
        id: quick_eval
        run: |
          # Sample 50 queries from dataset
          pnpm exec tsx eval/runQuickEval.ts
        continue-on-error: true
      
      - name: Upload Quick Eval Report
        uses: actions/upload-artifact@v4
        with:
          name: quick-eval-report-${{ github.sha }}
          path: eval/reports/quick-eval-*.md
      
      - name: Comment PR with Results
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const reportPath = 'eval/reports/quick-eval-latest.md';
            if (fs.existsSync(reportPath)) {
              const report = fs.readFileSync(reportPath, 'utf8');
              const body = `## üß™ Quick Evaluation Results\n\n${report}\n\n*This is a warn-only check. Full evaluation runs on merge.*`;
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.name,
                body: body
              });
            }
  
  full-eval-main:
    name: Full Eval (200 queries, fail mode)
    if: github.event_name == 'push' && github.ref == 'refs/heads/main' || github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for baseline comparison
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 10
      
      - name: Install dependencies
        run: pnpm install
      
      - name: Load Baseline Results
        id: baseline
        run: |
          if [ -f eval/results/baseline-v1.json ]; then
            echo "baseline_exists=true" >> $GITHUB_OUTPUT
          else
            echo "baseline_exists=false" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è No baseline found, this will become the new baseline"
          fi
      
      - name: Run Full Evaluation (200 queries)
        id: full_eval
        run: |
          pnpm exec tsx eval/runFullEval.ts
      
      - name: Check Quality Gates
        id: quality_gates
        run: |
          pnpm exec tsx eval/checkQualityGates.ts
      
      - name: Upload Full Eval Report
        uses: actions/upload-artifact@v4
        with:
          name: full-eval-report-${{ github.sha }}
          path: |
            eval/reports/full-eval-*.md
            eval/results/full-eval-*.json
      
      - name: Compare with Baseline
        if: steps.baseline.outputs.baseline_exists == 'true'
        id: compare
        run: |
          pnpm exec tsx eval/compareWithBaseline.ts
      
      - name: Upload Comparison Report
        if: steps.compare.outcome == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: comparison-report-${{ github.sha }}
          path: eval/reports/comparison-*.md
      
      - name: Fail on Quality Gate Violations
        if: steps.quality_gates.outputs.gates_passed != 'true'
        run: |
          echo "‚ùå Quality gates FAILED"
          echo "See artifacts for detailed report"
          exit 1
      
      - name: Create Issue on Regression
        if: failure() && steps.compare.outputs.regression_detected == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const title = 'üö® Evaluation Regression Detected';
            const body = `## Quality Gate Failure
            
            A regression was detected in the latest evaluation run.
            
            **Commit**: ${{ github.sha }}
            **Workflow**: ${{ github.run_id }}
            
            See artifacts for detailed comparison report.
            
            ### Failed Metrics:
            ${{ steps.quality_gates.outputs.failed_metrics }}
            
            ### Action Required:
            1. Review the comparison report
            2. Identify root cause
            3. Fix and re-run evaluation
            4. Update baseline if intentional change
            `;
            
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.name,
              title: title,
              body: body,
              labels: ['evaluation-regression', 'priority:high']
            });

  ablation-benchmark:
    name: Ablation Benchmark (strategy comparison)
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'schedule'
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 10
      
      - name: Install dependencies
        run: pnpm install
      
      - name: Run Ablation Benchmark
        run: |
          pnpm exec tsx eval/runAblation.ts
      
      - name: Upload Ablation Report
        uses: actions/upload-artifact@v4
        with:
          name: ablation-report-${{ github.sha }}
          path: |
            eval/reports/ablation-*.md
            eval/results/ablation-*.json
